{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BinaryClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3PVyvnv2PQfnRqK50iV0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsniranjan/ShipTruckClassifier/blob/main/BinaryClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-EKiFakFgre"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx6wkpsmS-s4"
      },
      "source": [
        "###Here, we'll take CIFAR10 dataset and extract the ship and truck images from it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ5zvOV6F1e8",
        "outputId": "d5818642-686c-40c0-dc6b-209374bb1291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(trainX, trainY),(testX,testY)=datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJhE2MX2Qz8G",
        "outputId": "22eb9743-0146-4601-e56b-8defbd172797"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5oFKQ-Ow5o"
      },
      "source": [
        "trainY=trainY.reshape(-1,)\n",
        "testY=testY.reshape(-1,)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk3ls3uoPD3j"
      },
      "source": [
        "trainX=trainX/255\n",
        "testX=testX/255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njN22_TGksc4",
        "outputId": "eac4165d-051f-4065-c08a-65c26b27f709"
      },
      "source": [
        "shipcount=0\n",
        "truckcount=0\n",
        "for y in trainY:\n",
        "  if(y==8):\n",
        "    shipcount+=1\n",
        "  elif(y==9):\n",
        "    truckcount+=1\n",
        "print(shipcount)\n",
        "print(truckcount)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inUZ3C0pQ5Wd",
        "outputId": "a8e29a64-f389-4e56-eb15-06cf792685e9"
      },
      "source": [
        "STtrainX=[]\n",
        "STtrainY=[]\n",
        "\n",
        "for index in range(50000):\n",
        "  if(trainY[index]==9 or trainY[index]==8):\n",
        "    STtrainX.append(trainX[index])\n",
        "    STtrainY.append(trainY[index])\n",
        "print(len(STtrainX))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzbSr177fdFA",
        "outputId": "e097bdce-cc5d-4a79-dc61-72f925a36185"
      },
      "source": [
        "STtestX=[]\n",
        "STtestY=[]\n",
        "\n",
        "for index in range(10000):\n",
        "  if(testY[index]==9 or testY[index]==8):\n",
        "    STtestX.append(testX[index])\n",
        "    STtestY.append(testY[index])\n",
        "print(len(STtestX))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ton5QDRJMwOa",
        "outputId": "f7b1330f-05af-4640-bc92-971abae283d3"
      },
      "source": [
        "for _ in range(len(STtrainY)):\n",
        "  if(STtrainY[_]==8):\n",
        "    STtrainY[_]=0\n",
        "  else:\n",
        "    STtrainY[_]=1\n",
        "for _ in range(len(STtestY)):\n",
        "  if(STtestY[_]==8):\n",
        "    STtestY[_]=0\n",
        "  else:\n",
        "    STtestY[_]=1\n",
        "  \n",
        "print(STtrainY[:5])\n",
        "print(STtestY[:5])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 0, 1, 1]\n",
            "[0, 0, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZGJMtPRNSRG"
      },
      "source": [
        "# ann=models.Sequential([\n",
        "#                        layers.Flatten(input_shape=(32,32,3)),\n",
        "#                         layers.Dense(3000,activation='relu'),\n",
        "#                         layers.Dense(2,activation='softmax')\n",
        "# ])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YoHLcFBNkNU"
      },
      "source": [
        "# ann.compile(optimizer='SGD',\n",
        "#             loss='sparse_categorical_crossentropy',\n",
        "#             metrics=['accuracy']\n",
        "#           )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "estX52JuNomx"
      },
      "source": [
        "# ann.fit(np.array(STtrainX),np.array(STtrainY),epochs=10)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyA9ZU2JXg3b"
      },
      "source": [
        "# ann.evaluate(np.array(STtrainX),np.array(STtrainY))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaPMHdMYgCTZ"
      },
      "source": [
        "cnn= models.Sequential([\n",
        "                        layers.Conv2D(filters=5,kernel_size=(3,3),activation='relu',input_shape=(32,32,3)),\n",
        "                        layers.MaxPooling2D((2,2)),\n",
        "                        layers.Conv2D(filters=5,kernel_size=(3,3),activation='relu'),\n",
        "                        layers.MaxPooling2D((2,2)),\n",
        "                        layers.Flatten(),\n",
        "                        layers.Dense(10,activation='relu'),\n",
        "                        layers.Dense(2,activation='softmax')\n",
        "])\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP6A-MFRLWmj"
      },
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics='accuracy'\n",
        "          )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j1SsaTvMIbF",
        "outputId": "e0d3f4ed-b2a8-45ff-c605-89f0ef0c5eae"
      },
      "source": [
        "cnn.fit(np.array(STtrainX),np.array(STtrainY),epochs=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.5464 - accuracy: 0.7228\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3944 - accuracy: 0.8262\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 5s 18ms/step - loss: 0.3546 - accuracy: 0.8476\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3401 - accuracy: 0.8523\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3179 - accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3030 - accuracy: 0.8724\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.2912 - accuracy: 0.8803\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.2846 - accuracy: 0.8830\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.2707 - accuracy: 0.8880\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.2582 - accuracy: 0.8952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb31b24ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSt2D4ssX7dl",
        "outputId": "b064d127-9e9f-49aa-ea24-07a74ff913d8"
      },
      "source": [
        "cnn.evaluate(np.array(STtrainX),np.array(STtrainY))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2850 - accuracy: 0.8769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28499728441238403, 0.8769000172615051]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "050BGOONSxCX"
      },
      "source": [
        "##with cnn, we got an accuracy of 0.909"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQfVpmWpX6ZP"
      },
      "source": [
        "\n",
        "tf.keras.models.save_model(cnn,'mymodel.hdf5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_kTd3L4MU7k",
        "outputId": "5d7c44a6-f8f1-49d4-c7f1-192fdddaee2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U ipykernel\n",
        "!pip install -q streamlit"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (6.0.3)\n",
            "Requirement already satisfied: ipython<8.0,>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (7.26.0)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (0.1.2)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.0.0)\n",
            "Requirement already satisfied: tornado<7.0,>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: importlib-metadata<4 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (3.10.1)\n",
            "Requirement already satisfied: jupyter-client<7.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied: traitlets<6.0,>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.0.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->ipykernel) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->ipykernel) (3.5.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.18.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (3.0.19)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel) (57.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel) (0.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel) (2.8.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client<7.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets<6.0,>=4.1.0->ipykernel) (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sg8ZZ4SIrGz",
        "outputId": "a1b9c53e-eb1c-4ed3-fa67-5fde996dc8fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "st.title(\"Ship Truck Classifie\")\n",
        "st.text(\"Provide URL of  Image for image classification\")\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def load_model():\n",
        "  model = tf.keras.models.load_model('/content/mymodel.hdf5')\n",
        "  return model\n",
        "with st.spinner('Loading Model Into Memory....'):\n",
        "  model = load_model()\n",
        "\n",
        "classes=['ship','truck']\n",
        "\n",
        "def scale(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255.0\n",
        "\n",
        "  return tf.image.resize(image,[32,32])\n",
        "\n",
        "def decode_img(image):\n",
        "  img = tf.image.decode_jpeg(image, channels=3)\n",
        "  img = scale(img)\n",
        "  return np.expand_dims(img, axis=0)\n",
        "\n",
        "# path = st.text_input('Enter Image URL to Classify.. ','https://cdn.britannica.com/17/126517-050-9CDCBDDF/semi-semitrailer-truck-tractor-highway.jpg')\n",
        "# if path is not None:\n",
        "#     content = requests.get(path).content\n",
        "\n",
        "#     st.write(\"Predicted Class :\")\n",
        "#     with st.spinner('classifying.....'):\n",
        "#       label =np.argmax(model.predict(decode_img(content)),axis=1)\n",
        "#       st.write(classes[label[0]])    \n",
        "#     st.write(\"\")\n",
        "#     image = Image.open(BytesIO(content))\n",
        "#     st.image(image, caption='Classifying Image', use_column_width=True)\n",
        "\n",
        "file = st.file_uploader(\"Please upload an brain scan file\", type=[\"jpg\", \"png\"])\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "def import_and_predict(image_data, model):\n",
        "    \n",
        "        size = (32,32)    \n",
        "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
        "        image = np.asarray(image)\n",
        "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.\n",
        "        \n",
        "        img_reshape = img[np.newaxis,...]\n",
        "    \n",
        "        prediction = model.predict(img_reshape)\n",
        "        \n",
        "        return prediction\n",
        "if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    predictions = import_and_predict(image, model)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "    st.write(prediction)\n",
        "    st.write(score)\n",
        "    print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(classes[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wjsGr5nJN92",
        "outputId": "900ad830-238e-44bb-a3a9-b45a6fcb6be5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-11 21:53:28--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.82.179.106, 52.44.51.219, 54.243.172.172, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.82.179.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  18.8MB/s    in 0.7s    \n",
            "\n",
            "2021-08-11 21:53:29 (18.8 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcVtYpnlJUo9",
        "outputId": "55ca073b-4e85-4a8d-84e8-cf6b918c4ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9uPz6YpJXwl"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b14m6Mo-JZf1",
        "outputId": "5f98591a-87d7-4575-c09c-5635678a92f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execute the next cell and the go to the following URL: https://9a8ff4faa938.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eewl8BJcJdmM",
        "outputId": "f7752847-1c94-47f7-da14-d8ac5565bdd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!streamlit run /content/app.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-11 21:53:52.930935: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.223.98:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2021-08-11 21:53:54.395 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\", line 515, in get_or_create_cached_value\n",
            "    hash_funcs=hash_funcs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\", line 308, in _read_from_cache\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\", line 294, in _read_from_cache\n",
            "    mem_cache, key, allow_output_mutation, func_or_code, hash_funcs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\", line 212, in _read_from_mem_cache\n",
            "    raise CacheKeyNotFoundError(\"Key not found in mem cache\")\n",
            "streamlit.caching.CacheKeyNotFoundError: Key not found in mem cache\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 350, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 18, in <module>\n",
            "    model = load_model()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\", line 543, in wrapped_func\n",
            "    return get_or_create_cached_value()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\", line 527, in get_or_create_cached_value\n",
            "    return_value = func(*args, **kwargs)\n",
            "  File \"/content/app.py\", line 15, in load_model\n",
            "    model = tf.keras.models.load_model('/content/mymodel.hdf5')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\", line 206, in load_model\n",
            "    return saved_model_load.load(filepath, compile, options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 121, in load\n",
            "    meta_graph_def = loader_impl.parse_saved_model(path).meta_graphs[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 116, in parse_saved_model\n",
            "    constants.SAVED_MODEL_FILENAME_PB))\n",
            "OSError: SavedModel file does not exist at: /content/mymodel.hdf5/{saved_model.pbtxt|saved_model.pb}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIlsushCRQit"
      },
      "source": [
        "##Please bare any issues with ngrok"
      ]
    }
  ]
}